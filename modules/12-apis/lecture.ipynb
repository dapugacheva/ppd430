{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs and Scraping\n",
    "\n",
    "Overview of today's topic:\n",
    "\n",
    "  - What are APIs and how do you work with them?\n",
    "  - Geocoding place names and addresses\n",
    "  - Reverse-geocoding coordinates\n",
    "  - Looking up places near some location\n",
    "  - Web scraping when no API is provided\n",
    "  - Using data portals programmatically\n",
    "\n",
    "To follow along with this lecture, you need a working Google API key to use the Google Maps Geocoding API and the Google Places API Web Service. These APIs require you to set up billing info, but we won't use them in class beyond the free threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import GoogleV3\n",
    "\n",
    "from keys import google_api_key\n",
    "\n",
    "# define a pause duration between API requests\n",
    "pause = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An API is an application programming interface. It provides a structured way to send commands or requests to a piece of software. \"API\" often refers to a web service API. This is like web site (but designed for applications, rather than humans, to use) that you can send requests to to execute commands or query for data. Today, REST APIs are the most common. To use them, you simply send them a request, and they reply with a response, similar to how a web browser works. The request is sent to an endpoint (a URL) typically with a set of parameters to provide the details of your query or command.\n",
    "\n",
    "In the example below, we make a request to the [ipify](https://www.ipify.org/) API and request a JSON formatted response. Then we look up the location of the IP address it returned, using the [ip-api](https://ip-api.com/) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is your current public IP address?\n",
    "url = 'https://api.ipify.org?format=json'\n",
    "data = requests.get(url).json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and what is the location of that IP address?\n",
    "url = 'http://ip-api.com/json/{}'.format(data['ip'])\n",
    "requests.get(url).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the current weather? Use the [National Weather Service](https://www.weather.gov/documentation/services-web-api) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for the forecast url for a pair of lat-lng coords\n",
    "location = '34.019268,-118.283554'\n",
    "url = 'https://api.weather.gov/points/{}'.format(location)\n",
    "data = requests.get(url).json()\n",
    "\n",
    "# extract the forecast url and retrieve it\n",
    "forecast_url = data['properties']['forecast']\n",
    "forecast = requests.get(forecast_url).json()\n",
    "\n",
    "# convert the forecast to a dataframe\n",
    "pd.DataFrame(forecast['properties']['periods']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use any web service's API in this same basic way: request the URL with some parameters. Read the API's documentation to know how to use it and what to send. You can also use many web service's through a Python package to make complex services easier to work with. For example, there's a fantastic package called [cenpy](https://cenpy-devs.github.io/cenpy/) that makes downloading and working with US census data super easy.\n",
    "\n",
    "## 1. Geocoding\n",
    "\n",
    "\"Geocoding\" means converting a text description of some place (such as the place's name or its address) into geographic coordinates identifying the place's location on Earth. These geographic coordinates may take the form of a single latitude-longitude coordinate pair, or a bounding box, or a boundary polygon, etc.\n",
    "\n",
    "### 1a. Geocoding place names with OpenStreetMap via OSMnx\n",
    "\n",
    "[OpenStreetMap](https://www.openstreetmap.org/) is a worldwide mapping platform that anyone can contribute to. [OSMnx](https://github.com/gboeing/osmnx) is a Python package to work with OpenStreetMap for geocoding, downloading geospatial data, and modeling/analyzing networks. OpenStreetMap and OSMnx are free to use and do not require an API key. We'll work with OSMnx more in a couple weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode a place name to lat-lng\n",
    "place = 'University of Southern California'\n",
    "latlng = ox.geocode(place)\n",
    "latlng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode a series of place names to lat-lng\n",
    "places = pd.Series(['San Diego, California',\n",
    "                    'Los Angeles, California',\n",
    "                    'San Francisco, California',\n",
    "                    'Seattle, Washington',\n",
    "                    'Vancouver, British Columbia'])\n",
    "coords = places.map(ox.geocode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out lats and lngs to individual columns in a dataframe\n",
    "pd.DataFrame({'place': places,\n",
    "              'lat': coords.map(lambda x: x[0]),\n",
    "              'lng': coords.map(lambda x: x[1])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of lat-lng coordinates, we can also geocode place names to their place's *boundaries* with OSMnx. This essentially looks-up the place in OpenStreetMap's database (note: that means the place has to exist in its database!) then returns its details, including geometry and bounding box, as a GeoPandas GeoDataFrame. We'll review GeoDataFrames next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode a list of place names to a GeoDataFrame\n",
    "# by default, OSMnx retrieves the first [multi]polygon object\n",
    "# specify which_result=1 to retrieve the top match, regardless of geometry type\n",
    "gdf_places = ox.geocode_to_gdf(places.to_list(), which_result=1)\n",
    "gdf_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode a single place name to a GeoDataFrame\n",
    "gdf = ox.geocode_to_gdf(place)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the value from row 0's geometry column\n",
    "polygon = gdf['geometry'].iloc[0]\n",
    "polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use OSMnx to query for geospatial entities within USC's boundary polygon. You can specify what kind of entities to retrieve by using a `tags` dictionary. In a couple weeks we'll see how to model street networks within a place's boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the buildings within that polygon\n",
    "tags = {'building': True}\n",
    "gdf_bldg = ox.geometries_from_polygon(polygon, tags)\n",
    "gdf_bldg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the building footprints\n",
    "fig, ax = ox.plot_footprints(gdf_bldg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# get all the building footprints within santa monica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: Geocoding addresses to lat-lng\n",
    "\n",
    "You can geocode addresses as well with OpenStreetMap, but it can be a little hit-or-miss compared to the data coverage of commercial closed-source services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode an address to lat-lng\n",
    "address = '704 S Alvarado St, Los Angeles, California'\n",
    "latlng = ox.geocode(address)\n",
    "latlng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Google Maps geocoding API. Their geocoder is very powerful, but you do have to pay for it beyond a certain threshold of free usage.\n",
    "\n",
    "Documentation: https://developers.google.com/maps/documentation/geocoding/start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.DataFrame(['704 S Alvarado St, Los Angeles, CA',\n",
    "                          '100 Larkin St, San Francisco, CA',\n",
    "                          '350 5th Ave, New York, NY'], columns=['address'])\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function accepts an address string, sends it to Google API, returns lat-lng result\n",
    "def geocode(address, print_url=False):\n",
    "    \n",
    "    # pause for some duration before each request, to not hammer their server\n",
    "    time.sleep(pause)\n",
    "    \n",
    "    # api url with placeholders to fill in with variables' values\n",
    "    url_template = 'https://maps.googleapis.com/maps/api/geocode/json?address={}&key={}'\n",
    "    url = url_template.format(address, google_api_key)\n",
    "    if print_url: print(url)\n",
    "    \n",
    "    # send request to server, get response, and convert json string to dict\n",
    "    data = requests.get(url).json()\n",
    "    \n",
    "    # if results were returned, extract lat-lng from top result\n",
    "    if len(data['results']) > 0:\n",
    "        lat = data['results'][0]['geometry']['location']['lat']\n",
    "        lng = data['results'][0]['geometry']['location']['lng']\n",
    "        \n",
    "        # return lat-lng as a string\n",
    "        return '{},{}'.format(lat, lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function\n",
    "geocode('350 5th Ave, New York, NY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each value in the address column, geocode it, save results as new column\n",
    "locations['latlng'] = locations['address'].map(geocode)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the result into separate lat and lng columns, if desired\n",
    "locations[['lat', 'lng']] = pd.DataFrame(data=locations['latlng'].str.split(',').to_list())\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# create a new pandas series of 3 addresses and use our function to geocode them\n",
    "# then create a new pandas series of 3 famous site names and use our function to geocode them\n",
    "# create new variables to contain your work so as to not overwrite the locations df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Places API\n",
    "\n",
    "We will use Google's Places API to look up places in the vicinity of some location.\n",
    "\n",
    "Documentation: https://developers.google.com/places/web-service/intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google places API URL, with placeholders\n",
    "url_template = 'https://maps.googleapis.com/maps/api/place/search/json?keyword={}&location={}&radius={}&key={}'\n",
    "\n",
    "# what keyword to search for\n",
    "keyword = 'restaurant'\n",
    "\n",
    "# define the radius (in meters) for the search\n",
    "radius = 500\n",
    "\n",
    "# define the location coordinates\n",
    "location = '34.019268,-118.283554'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add our variables into the url, submit the request to the api, and load the response\n",
    "url = url_template.format(keyword, location, radius, google_api_key)\n",
    "response = requests.get(url)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many results did we get?\n",
    "len(data['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a result\n",
    "data['results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the results into a dataframe of places\n",
    "places = pd.DataFrame(data=data['results'],\n",
    "                      columns=['name', 'geometry', 'rating', 'vicinity'])\n",
    "places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out lat-long and return it as a series\n",
    "# this creates a dataframe of all the results when you .apply()\n",
    "def parse_coords(geometry):\n",
    "    if isinstance(geometry, dict):\n",
    "        lng = geometry['location']['lng']\n",
    "        lat = geometry['location']['lat']\n",
    "        return pd.Series({'lat':lat, 'lng':lng})\n",
    "    \n",
    "# test our function\n",
    "places['geometry'].head().apply(parse_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run our function on the whole dataframe and save the output to 2 new dataframe columns\n",
    "places[['lat', 'lng']] = places['geometry'].apply(parse_coords)\n",
    "places_clean = places.drop('geometry', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the places by rating\n",
    "places_clean = places_clean.sort_values(by='rating', ascending=False)\n",
    "places_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# find the five highest-rated bars within 1/2 mile of pershing square\n",
    "# create new variables to contain your work so as to not overwrite places and places_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reverse geocoding\n",
    "\n",
    "Reverse geocoding, as you might expect from its name, does the opposite of regular geocoding: it takes a pair of coordinates on the Earth's surface and looks up what address or place corresponds to that location.\n",
    "\n",
    "We'll use Google's reverse geocoding API. Documentation: https://developers.google.com/maps/documentation/geocoding/intro#ReverseGeocoding\n",
    "\n",
    "As we saw with OSMnx, you often don't have to query the API yourself manually: many popular APIs have dedicated Python packages to work with them. You *can* do this manually, just like in the previous Google examples, but it's a little more complicated to parse Google's address component results. If we just want addresses, we can use [geopy](https://geopy.readthedocs.io/) to simply interact with Google's API automatically for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use the points from the Places API, but you could use any point data here\n",
    "points = places_clean[['lat', 'lng']].head()\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column to put lat-lng into the format google likes\n",
    "points['latlng'] = points.apply(lambda row: '{},{}'.format(row['lat'], row['lng']), axis='columns')\n",
    "points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell geopy to reverse geocode using Google's API and return address\n",
    "def reverse_geopy(latlng):\n",
    "    time.sleep(pause)\n",
    "    geocoder = GoogleV3(api_key=google_api_key)\n",
    "    address, _ = geocoder.reverse(latlng, exactly_one=True)\n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now reverse-geocode the points to addresses\n",
    "points['address'] = points['latlng'].map(reverse_geopy)\n",
    "points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if you just want the city or state?\n",
    "You could try to parse the address strings, but you're relying on them always having a consistent format. This might not be the case if you have international location data. In this case, you should call the API manually and extract the individual address components you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the Google API latlng data to reverse geocode it\n",
    "def reverse_geocode(latlng):\n",
    "    time.sleep(pause)\n",
    "    url_template = 'https://maps.googleapis.com/maps/api/geocode/json?latlng={}&key={}'\n",
    "    url = url_template.format(latlng, google_api_key)\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if len(data['results']) > 0:\n",
    "        return data['results'][0]\n",
    "    \n",
    "geocode_results = points['latlng'].map(reverse_geocode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_results.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look inside each reverse geocode result to see if address_components exists. If it does, look inside each component to see if we can find the city or the state. Google calls the city name by the abstract term 'locality' and the state name by the abstract term 'administrative_area_level_1' ...this lets them use consistent terminology anywhere in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city(geocode_result):\n",
    "     if 'address_components' in geocode_result:\n",
    "        for address_component in geocode_result['address_components']:\n",
    "            if 'locality' in address_component['types']:\n",
    "                return address_component['long_name']\n",
    "                \n",
    "def get_state(geocode_result):\n",
    "     if 'address_components' in geocode_result:\n",
    "        for address_component in geocode_result['address_components']:\n",
    "            if 'administrative_area_level_1' in address_component['types']:\n",
    "                return address_component['long_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now map our functions to extract city and state names\n",
    "points['city'] = geocode_results.map(get_city)                \n",
    "points['state'] = geocode_results.map(get_state)\n",
    "points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# write a new function get_neighborhood() to parse the neighborhood name and add it to the points df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Web Scraping\n",
    "\n",
    "If you need data from a web page that doesn't offer an API, you can scrape it. Note that many web sites prohibit scraping in their terms of use, so proceed respectfully and cautiously. Web scraping means downloading a web page, parsing individual data out of its HTML, and converting those data into a structured dataset.\n",
    "\n",
    "For straightforward web scraping tasks, you can use the powerful BeautifulSoup package. However, some web pages load content dynamically using JavaScript. For such complex web scraping tasks, consider using the Selenium browser automation package.\n",
    "\n",
    "In this example, we'll scrape https://en.wikipedia.org/wiki/List_of_National_Basketball_Association_arenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_National_Basketball_Association_arenas'\n",
    "response = requests.get(url)\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the html string\n",
    "html[5000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html\n",
    "soup = BeautifulSoup(html, features='html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = soup.find('tbody').findAll('tr')\n",
    "#rows\n",
    "#rows[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in rows[1:]:\n",
    "    cells = row.findAll('td')\n",
    "    d = [cell.text.strip('\\n') for cell in cells[1:-1]]\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arena', 'city', 'team', 'capacity', 'opened']\n",
    "df = pd.DataFrame(data=data, columns=cols).dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip out all the wikipedia notes in square brackets\n",
    "df = df.applymap(lambda x: re.sub(r'\\[.\\]', '', x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert capacity and opened to integer\n",
    "df['capacity'] = df['capacity'].str.replace(',', '')\n",
    "df[['capacity', 'opened']] = df[['capacity', 'opened']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('capacity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is really hard! It takes lots of practice. If you want to use it, read the BeautifulSoup and Selenium documentation carefully, and then practice, practice, practice. You'll be an expert before long.\n",
    "\n",
    "## 5. Data Portals\n",
    "\n",
    "Many governments and agencies now open up their data to the public through a data portal. These often offer APIs to query them for real-time data. This example uses the LA Open Data Portal... browse the portal for public datasets: https://data.lacity.org/browse\n",
    "\n",
    "Let's look at parking meter data for those that have sensors telling us if they're currently occupied or vacant: https://data.lacity.org/A-Livable-and-Sustainable-City/LADOT-Parking-Meter-Occupancy/e7h6-4a3e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define API endpoint\n",
    "url = 'https://data.lacity.org/resource/e7h6-4a3e.json'\n",
    "\n",
    "# request the URL and download its response\n",
    "response = requests.get(url)\n",
    "\n",
    "# parse the json string into a Python dict\n",
    "data = response.json()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the json data into a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have parking space ID, occupancy status, and reporting time. But we don't know where these spaces are! Fortunately the LA GeoHub has sensor location data: http://geohub.lacity.org/datasets/parking-meter-sensors/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define API endpoint\n",
    "url = 'https://opendata.arcgis.com/datasets/723c00530ea441deaa35f25e53d098a8_16.geojson'\n",
    "\n",
    "# request the URL and download its response\n",
    "response = requests.get(url)\n",
    "\n",
    "# parse the json string into a Python dict\n",
    "data = response.json()\n",
    "len(data['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# turn the geojson data into a geodataframe\n",
    "gdf = gpd.GeoDataFrame.from_features(data)\n",
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns are in our data?\n",
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge sensor locations with current occupancy status\n",
    "parking = pd.merge(left=gdf, right=df, left_on='SENSOR_UNIQUE_ID', right_on='spaceid', how='inner')\n",
    "parking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking = parking[['occupancystate', 'geometry', 'ADDRESS_SPACE']]\n",
    "\n",
    "# extract lat and lon from geometry column\n",
    "parking['lon'] = parking['geometry'].x\n",
    "parking['lat'] = parking['geometry'].y\n",
    "\n",
    "parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many vacant vs occupied spots are there right now?\n",
    "parking['occupancystate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map it\n",
    "vacant = parking[parking['occupancystate'] == 'VACANT']\n",
    "ax = vacant.plot(c='b', markersize=1, alpha=0.5)\n",
    "\n",
    "occupied = parking[parking['occupancystate'] == 'OCCUPIED']\n",
    "ax = vacant.plot(ax=ax, c='r', markersize=1, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's impossible to see! At this scale, all the vacant spots are obscured by occupied spots next to them. It would be much better if we had an interactive map. We'll use folium more in coming weeks to create interactive web maps, but here's a preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create leaflet web map centered/zoomed to downtown LA\n",
    "m = folium.Map(location=(34.05, -118.25), zoom_start=15, tiles='cartodbpositron')\n",
    "\n",
    "# add blue markers for each vacant spot\n",
    "cols = ['lat', 'lon', 'ADDRESS_SPACE']\n",
    "for lat, lng, address in vacant[cols].values:\n",
    "    folium.CircleMarker(location=(lat, lng), radius=5, color='#3186cc',\n",
    "                        fill=True, fill_color='#3186cc', tooltip=address).add_to(m)\n",
    "\n",
    "# add red markers for each occupied spot\n",
    "for lat, lng, address in occupied[cols].values:  \n",
    "    folium.CircleMarker(location=(lat, lng), radius=5, color='#dc143c',\n",
    "                        fill=True, fill_color='#dc143c', tooltip=address).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now view the web map we created\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual exercise\n",
    "\n",
    "1. Visit the LA data portal (link provided above) or another data portal and identify a different data set of interest\n",
    "1. Download it using Python as we did above\n",
    "1. Clean the data set if necessary and calculate descriptive stats for 2 or more columns\n",
    "1. Map the data. Do you see any patterns of interest?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
